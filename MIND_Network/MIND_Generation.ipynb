{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working directory set to: /Users/melinatsotras/Desktop/submission\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# For Jupyter or interactive use — use current working directory as script base\n",
    "notebook_path = Path().resolve()\n",
    "\n",
    "# Assume notebook is in a subfolder of the repo — go up one level\n",
    "file_dir = notebook_path.parent\n",
    "\n",
    "# Set working directory to the repo root\n",
    "os.chdir(file_dir)\n",
    "print(\"Working directory set to:\", Path.cwd())\n",
    "\n",
    "sys.path.append(str(file_dir))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree as KDTree\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "\n",
    "data_dir = f\"{file_dir}/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for MIND Construction from https://github.com/isebenius/MIND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(points, thresh=7): #taken from https://stackoverflow.com/questions/22354094/pythonic-way-of-detecting-outliers-in-one-dimensional-observation-data\n",
    "\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        thresh : The modified z-score to use as a threshold. Observations with\n",
    "            a modified z-score (based on the median absolute deviation) greater\n",
    "            than this value will be classified as outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "\n",
    "    References:\n",
    "    ----------\n",
    "        Boris Iglewicz and David Hoaglin (1993), \"Volume 16: How to Detect and\n",
    "        Handle Outliers\", The ASQC Basic References in Quality Control:\n",
    "        Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. \n",
    "    \"\"\"\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh\n",
    "\n",
    "def get_KDTree(x): #Inspired by https://gist.github.com/atabakd/ed0f7581f8510c8587bc2f41a094b518\n",
    "\n",
    "    # Check the dimensions are consistent\n",
    "    x = np.atleast_2d(x)\n",
    "    \n",
    "    # Build a KD tree representation of the samples\n",
    "    xtree = KDTree(x)\n",
    "    \n",
    "    return xtree\n",
    "\n",
    "def get_KL(x, y, xtree, ytree): #Inspired by https://gist.github.com/atabakd/ed0f7581f8510c8587bc2f41a094b518\n",
    "\n",
    "    \n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "    \n",
    "    x = np.atleast_2d(x)\n",
    "    y = np.atleast_2d(y)\n",
    "\n",
    "    n,d = x.shape\n",
    "    m,dy = y.shape\n",
    "    \n",
    "    #Check dimensions\n",
    "    assert(d == dy)\n",
    "\n",
    "    # Get the first two nearest neighbours for x, since the closest one is the\n",
    "    # sample itself.\n",
    "    r = xtree.query(x, k=2, eps=.01, p=2)[0][:,1]\n",
    "    s = ytree.query(x, k=1, eps=.01, p=2)[0]\n",
    "    \n",
    "    rs_ratio = r/s\n",
    "\n",
    "    #Remove points with zero, nan, or infinity. This happens when two regions have a vertex with the exact same value – an occurence that basically onnly happens for the single feature MSNs\n",
    "    #and has to do with FreeSurfer occasionally outputting the exact same value for different vertices.\n",
    "    rs_ratio = rs_ratio[np.isfinite(rs_ratio)]\n",
    "    rs_ratio = rs_ratio[rs_ratio!=0.0]\n",
    "    \n",
    "    # There is a mistake in the paper. In Eq. 14, the right side misses a negative sign\n",
    "    # on the first term of the right hand side.\n",
    "\n",
    "    kl = -np.log(rs_ratio).sum() * d / n + np.log(m / (n - 1.))\n",
    "    kl = np.maximum(kl, 0)\n",
    "    \n",
    "    return kl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mind_network(data_df, feature_cols, region_list, resample=False, n_samples = 4000):\n",
    "\n",
    "    MIND = pd.DataFrame(np.zeros((len(region_list), len(region_list))), \\\n",
    "                        index = region_list, columns = region_list)\n",
    "\n",
    "    #Get only desired regions\n",
    "    data_df = data_df.loc[data_df['Label'].isin(region_list)]\n",
    "    \n",
    "    #Resample dataset if resample has been set to True and if it is UNIVARIATE ONLY. This should only be done if you are using a single feature which contains repeated values.\n",
    "    if (len(feature_cols) == 1) and resample==True:   \n",
    "        n_samples = n_samples\n",
    "        resampled_dataset = pd.DataFrame(np.zeros((n_samples, len(region_list))), columns = region_list)\n",
    "\n",
    "        for name, data in data_df.groupby('Label'):\n",
    "            resampled_dataset[name] = stats.gaussian_kde(data[feature_cols[0]]).resample(n_samples)[0]\n",
    "\n",
    "        resampled_dataset = resampled_dataset.melt(var_name = 'Label', value_name = feature_cols[0])\n",
    "        data_df = resampled_dataset\n",
    "\n",
    "    if (len(feature_cols) > 1) and resample==True:   \n",
    "        raise Exception(\"Resampling the data is only supported if you are using a single feature -- this is because higher order density estimation can be unreliable and very computationally expensive.\")\n",
    "\n",
    "    #Check that there aren't many repeated values\n",
    "    percent_unique_vals = len(data_df[feature_cols].drop_duplicates())/len(data_df[feature_cols])\n",
    "    \n",
    "    if percent_unique_vals < 0.8:\n",
    "        raise Exception(\"There are many repeated values in the data, which compromises the validity of MIND calculation. Please minimize the number of repeated values in the data and try again. If you are using only one feature, try rerunning with resample=True.\")\n",
    "\n",
    "    grouped_data = data_df.groupby('Label')\n",
    "\n",
    "    KDtrees = defaultdict(object)\n",
    "\n",
    "    for i, (name_x, dat_x) in enumerate(grouped_data):\n",
    "        tree = get_KDTree(dat_x[feature_cols])\n",
    "        KDtrees[name_x] = tree\n",
    "    \n",
    "    used_pairs = []\n",
    "    \n",
    "    for i, (name_x, dat_x) in enumerate(grouped_data):\n",
    "        \n",
    "        for name_y, dat_y in grouped_data:\n",
    "            if name_x == name_y:\n",
    "                continue\n",
    "\n",
    "            if set([name_x,name_y]) in used_pairs:\n",
    "                continue\n",
    "\n",
    "            dat_x = dat_x[feature_cols]\n",
    "            dat_y = dat_y[feature_cols]\n",
    "\n",
    "            KLa = get_KL(dat_x, dat_y, KDtrees[name_x], KDtrees[name_y])\n",
    "            KLb = get_KL(dat_y, dat_x, KDtrees[name_y], KDtrees[name_x])\n",
    "\n",
    "            kl = KLa + KLb\n",
    "\n",
    "            MIND.at[name_x,name_y] = 1/(1+kl)\n",
    "            MIND.at[name_y,name_x] = 1/(1+kl)\n",
    "\n",
    "            used_pairs.append(set([name_x,name_y]))\n",
    "\n",
    "    MIND = MIND[region_list].T[region_list].T\n",
    "    \n",
    "    return MIND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the MINDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33002</td>\n",
       "      <td>F</td>\n",
       "      <td>20.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34884</td>\n",
       "      <td>M</td>\n",
       "      <td>18.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35241</td>\n",
       "      <td>F</td>\n",
       "      <td>18.114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35253</td>\n",
       "      <td>M</td>\n",
       "      <td>19.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35580</td>\n",
       "      <td>M</td>\n",
       "      <td>17.273</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject sex     age\n",
       "0    33002   F  20.339\n",
       "1    34884   M  18.311\n",
       "2    35241   F  18.114\n",
       "3    35253   M  19.154\n",
       "4    35580   M  17.273"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load demographic data\n",
    "demographics = pd.read_csv(f'{data_dir}/demographics_v2.csv')\n",
    "display(demographics.head())\n",
    "\n",
    "# Extract subjects\n",
    "subjects = demographics['subject']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Save MINDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store MIND network data\n",
    "MIND_dict = {}\n",
    "\n",
    "# List of features to be used in the calculation (already z-scored)\n",
    "feature_list = ['surface_area', 'volume', 'mean_curvature', 'gauss_curvature', 'sulcal_depth', 'thickness', 'ratio']\n",
    "\n",
    "# Process each subject\n",
    "for sub in subjects:\n",
    "    # Read subject-specific MRI data\n",
    "    sub_df = pd.read_csv(f'{dir}/MIND_Network/MRI_input/{sub}_MRI_DATA.csv')\n",
    "    \n",
    "    # Log the subject being processed\n",
    "    print(f'Processing subject: {sub}')\n",
    "    \n",
    "    # Calculate and store the MIND network for the current subject\n",
    "    MIND_dict[sub] = calculate_mind_network(sub_df, feature_list, list(sub_df['Label'].unique()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save MIND network\n",
    "for sub in subjects:\n",
    "   MIND_dict[sub].to_csv(f'{dir}/MIND_Network/MINDS_per_subject/{sub}_MIND_sa_vol_mc_gc_sd_ct_ratio.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MINDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading subject: 33002\n",
      "Loading subject: 34884\n",
      "Loading subject: 35241\n",
      "Loading subject: 35253\n",
      "Loading subject: 35580\n",
      "Loading subject: 36657\n",
      "Loading subject: 37693\n",
      "Loading subject: 39437\n",
      "Loading subject: 39599\n",
      "Loading subject: 39834\n",
      "Loading subject: 40706\n",
      "Loading subject: 41083\n",
      "Loading subject: 41372\n",
      "Loading subject: 41645\n",
      "Loading subject: 41759\n",
      "Loading subject: 44444\n",
      "Loading subject: 49134\n",
      "Loading subject: 47979\n",
      "Loading subject: 48184\n",
      "Loading subject: 48233\n",
      "Loading subject: 49041\n",
      "Loading subject: 49050\n",
      "Loading subject: 49078\n",
      "Loading subject: 49112\n",
      "Loading subject: 49196\n",
      "Loading subject: 49225\n",
      "Loading subject: 42019\n",
      "Loading subject: 41807\n",
      "Loading subject: 41716\n",
      "Loading subject: 41854\n",
      "Loading subject: 41651\n",
      "Loading subject: 41547\n",
      "Loading subject: 41519\n",
      "Loading subject: 41463\n",
      "Loading subject: 41458\n",
      "Loading subject: 40033\n",
      "Loading subject: 39066\n",
      "Loading subject: 37972\n",
      "Loading subject: 36824\n",
      "Loading subject: 36464\n",
      "Loading subject: 36291\n",
      "Loading subject: 34847\n",
      "Loading subject: 34110\n",
      "Loading subject: 33111\n",
      "Loading subject: 32479\n",
      "Loading subject: 32287\n",
      "Loading subject: 37169\n",
      "Loading subject: 36831\n",
      "Loading subject: 36374\n",
      "Loading subject: 36422\n",
      "Loading subject: 36574\n",
      "Loading subject: 36352\n",
      "Loading subject: 35949\n",
      "Loading subject: 35671\n",
      "Loading subject: 35545\n",
      "Loading subject: 35306\n",
      "Loading subject: 34839\n",
      "Loading subject: 33825\n",
      "Loading subject: 33734\n",
      "Loading subject: 33278\n",
      "Loading subject: 33199\n",
      "Loading subject: 33882\n",
      "Loading subject: 32924\n",
      "Loading subject: 29949\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store MIND data for each subject\n",
    "MINDs = {}\n",
    "\n",
    "# Process each subject\n",
    "for subject in subjects:\n",
    "    # Print the current subject being processed\n",
    "    print(f'Loading subject: {subject}')\n",
    "    \n",
    "    # Read the subject-specific MIND data, rename the first column, and set 'region' as the index\n",
    "    temp = pd.read_csv(f'{dir}/MIND_Network/MIND_output/{subject}_MIND_sa_vol_mc_gc_sd_ct_ratio.csv') \\\n",
    "        .rename(columns={'Unnamed: 0': 'region'}) \\\n",
    "        .set_index('region')\n",
    "    \n",
    "    # Store the processed data in the MINDs dictionary\n",
    "    MINDs[subject] = temp\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "macaque-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
